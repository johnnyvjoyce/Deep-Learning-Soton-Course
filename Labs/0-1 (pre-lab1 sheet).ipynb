{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "# https://colab.research.google.com/gist/jonhare/d98813b2224dddbb234d2031510878e1/notebook.ipynb#scrollTo=0KtFLvvUI5I3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00,  4.4766e+00, -1.0321e+15]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], dtype=torch.int32)\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# create an empty floating point tensor\n",
    "x = torch.empty(1, 3)\n",
    "print(x)\n",
    "\n",
    "# Creation of default floating point tensor (float32) filled with ones\n",
    "y = torch.ones(2,5)\n",
    "\n",
    "# Creation of Integer tensor from existing data; The bad way (because you've _explicitly_ created a CPU-backed Tensor)\n",
    "zbad = torch.IntTensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(zbad)\n",
    "\n",
    "# Creation of Integer tensor from existing data; The good way (this way allows you to specify device=... so it could be backed by the GPU)\n",
    "z = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.FloatTensor\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(x.size())\n",
    "print(x.shape) #usually used in preference to size()\n",
    "\n",
    "print(z.type()) # the underlying class; this will be dependent on the backing device (so there are different FloatTensor implementations for different devices)\n",
    "print(z.device) # the actual backing device (which isn't just cpu/gpu, but could tell you which gpu...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 1.1250, 1.1250]])\n",
      "tensor([[0.0000, 0.0000, 1.1250]])\n",
      "tensor([[1.1250, 1.1250, 1.1250]])\n"
     ]
    }
   ],
   "source": [
    "x[0,0] = 0 #setting a specific value\n",
    "print(x)\n",
    "\n",
    "x[0,1:2] = 0 #setting a range of values (the slice operator : works just like in numpy)\n",
    "print(x)\n",
    "\n",
    "# Setting all  the values. Note all in-place operations are suffixed with an underscore\n",
    "x.fill_(1.125)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1250)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(x.mean())\n",
    "print(x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "tensor(3.3750)\n",
      "3.375\n"
     ]
    }
   ],
   "source": [
    "print(x.sum().shape)\n",
    "print(x.sum())\n",
    "## 0d tensor can be converted back to a Python scalar with item()\n",
    "print(x.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(z.numpy())\n",
    "\n",
    "print(z.cpu().numpy())\n",
    "print(z[0,0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21., 41., 61.])\n",
      "tensor([-1., -1., -1.])\n",
      "tensor([110., 420., 930.])\n",
      "tensor([0.9091, 0.9524, 0.9677])\n",
      "_______\n",
      "tensor([100., 400., 900.])\n",
      "tensor([-0.5440,  0.9129, -0.9880])\n",
      "tensor([ True, False, False])\n",
      "tensor([ True,  True, False])\n",
      "tensor([ True, False, False])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([ 10., 20., 30.])\n",
    "y = torch.tensor([ 11., 21., 31.])\n",
    "\n",
    "print(x + y) #Tensor-Tensor addition (element-wise addition)\n",
    "print(x - y) #Tensor-Tensor subtraction (element-wise subtraction)\n",
    "print(x * y) #Hadamard product of two tensors\n",
    "print(x / y) #Hadamard division of two tensors\n",
    "\n",
    "print(\"_______\")\n",
    "\n",
    "print(x**2) #raising to a power\n",
    "print(torch.sin(x)) #applying sin element-wise\n",
    "print(x == 10) #element-wise boolean tests\n",
    "print(x <= 20) #element-wise boolean tests\n",
    "print((x <= 20) & (x==10)) #element-wise logical `and`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "tensor([30., 40., 30.])\n",
      "tensor([30., 40., 30.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([ 10., 20., 30.]) #x is a 1d tensor\n",
    "m = torch.tensor([[ 0., 0., 1. ],\n",
    "                  [ 0., 2., 0. ],\n",
    "                  [ 3., 0., 0. ]]) #m is a 2d tensor\n",
    "\n",
    "try:\n",
    "    print(torch.mm(m,x)) #torch.mm performs matrix-matrix multiplication; this will fail because .mm doesn't support broadcasting and the inputs have differing tensor order\n",
    "except Exception as e:\n",
    "    print(\"Error: \" + str(e))\n",
    "print(torch.matmul(m,x)) #torch.matmul performs matrix-matrix multiplication with broadcasting; it will automatically convert x to a 2d tensor so the multiplication can be performed\n",
    "print(m @ x) #ampersand is convienent short-hand notation for matmul\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([1, 3])\n",
      "tensor([[30.],\n",
      "        [40.],\n",
      "        [30.]])\n"
     ]
    }
   ],
   "source": [
    "#Unsqueezing tensors - this is something you'll probably see a lot; unsqueezing adds another dimensio\n",
    "\n",
    "x = torch.tensor([ 10., 20., 30.])\n",
    "print(x.shape)\n",
    "x.unsqueeze_(-1) #in-place unsqueeze, adding the new dimension in the last position (so we create a _column_ vector)\n",
    "print(x.shape)\n",
    "\n",
    "print(x.t().shape) #note .t() transposes a tensor\n",
    "\n",
    "print(torch.mm(m,x)) #  the previous .mm that failed because of mismatched sizes will now work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10., 20., 30.])\n"
     ]
    }
   ],
   "source": [
    "x2 = x.reshape(3) # back to where we started!\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
