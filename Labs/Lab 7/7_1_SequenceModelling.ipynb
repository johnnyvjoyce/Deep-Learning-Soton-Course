{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "40fe1c0748661d409405f09e9250edcf",
     "grade": false,
     "grade_id": "cell-f67b416b0411edc1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 1: Sequence Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ed5be3ed6978c8f54e5301bbb9d0d0bd",
     "grade": false,
     "grade_id": "cell-a328195514e4147d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "__Before starting, we recommend you enable GPU acceleration if you're running on Colab.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5d3c83086d3c94835d3f8510df7f8d0f",
     "grade": false,
     "grade_id": "cell-52dc2d0ecf866f90",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Execute this code block to install dependencies when running on colab\n",
    "try:\n",
    "    import torch\n",
    "except:\n",
    "    from os.path import exists\n",
    "    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "    cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "    accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "    !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl torchvision\n",
    "\n",
    "try: \n",
    "    import torchbearer\n",
    "except:\n",
    "    !pip install torchbearer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e9c1849d2839e6c1ebac8b563fe9d0bc",
     "grade": false,
     "grade_id": "cell-36906cd59153af5b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Markov chains\n",
    "\n",
    "We'll start our exploration of modelling sequences and building generative models using a 1st order Markov chain. The Markov chain is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. In our case we're going to learn a model over a set of characters from an English language text. The events, or states, in our model are the set of possible characters, and we'll learn the probability of moving from one character to the next.\n",
    "\n",
    "Let's start by loading the data from the web:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "508d37e774c4619f7c4706291f52c466",
     "grade": false,
     "grade_id": "cell-a592d788c1587e58",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://s3.amazonaws.com/text-datasets/nietzsche.txt to .\\nietzsche.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c6e79cbf9c42b38c091b69ea438ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets.utils import download_url\n",
    "import torch\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "# Read the data\n",
    "download_url('https://s3.amazonaws.com/text-datasets/nietzsche.txt', '.', 'nietzsche.txt', None)\n",
    "text = io.open('./nietzsche.txt', encoding='utf-8').read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a1b08d3393744a64f2d1991d8ddd3c1a",
     "grade": false,
     "grade_id": "cell-f345306b2d88866e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We now need to iterate over the characters in the text and count the times each transition happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8452011964d66c1c591df5d4f49c82b6",
     "grade": false,
     "grade_id": "cell-21c1c86b5d26778f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "transition_counts = dict()\n",
    "for i in range(0,len(text)-1):\n",
    "    currc = text[i]\n",
    "    nextc = text[i+1]\n",
    "    if currc not in transition_counts:\n",
    "        transition_counts[currc] = dict()\n",
    "    if nextc not in transition_counts[currc]:\n",
    "        transition_counts[currc][nextc] = 0\n",
    "    transition_counts[currc][nextc] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "73f178f03f644719a7684c942212b488",
     "grade": false,
     "grade_id": "cell-f93390ea74e0de36",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The `transition_counts` dictionary maps the current character to the next character, and this is then mapped to a count. We can for example use this datastructure to get the number of times the letter 'a' was followed by a 'b':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d37afa35d97a35848444cbffb3d4369c",
     "grade": false,
     "grade_id": "cell-ed4eee0105f3a0cf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transitions from 'a' to 'b': 813\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of transitions from 'a' to 'b': \" + str(transition_counts['a']['b']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "89b218435d0475de2fd126d6cf654d07",
     "grade": false,
     "grade_id": "cell-195d5f1aebd40797",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Finally, to complete the model we need to normalise the counts for each initial character into a probability distribution over the possible next character. We'll slightly modify the form we're storing these and maintain a tuple of array objects for each initial character: the first holding the set of possible characters, and the second holding the corresponding probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9dbad32065a0c97c65cc5760b5efa718",
     "grade": false,
     "grade_id": "cell-28d68d95d39e3180",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "transition_probabilities = dict()\n",
    "for currentc, next_counts in transition_counts.items():\n",
    "    values = []\n",
    "    probabilities = []\n",
    "    sumall = 0\n",
    "    for nextc, count in next_counts.items():\n",
    "        values.append(nextc)\n",
    "        probabilities.append(count)\n",
    "        sumall += count\n",
    "    for i in range(0, len(probabilities)):\n",
    "        probabilities[i] /= float(sumall)\n",
    "    transition_probabilities[currentc] = (values, probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7e7336b1ef946f10dc63020be2b17ecf",
     "grade": false,
     "grade_id": "cell-f79188db65a705aa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "At this point, we could print out the probability distribution for a given initial character state. For example, to print the distribution for 'a':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5eaaf96ae4181ad3a2b7087d9643ff1f",
     "grade": false,
     "grade_id": "cell-ee624b4c0ff2c64f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c 0.03685183172083922\n",
      "t 0.14721708881400153\n",
      "  0.05296771388194369\n",
      "n 0.2322806826829003\n",
      "l 0.11552886183280792\n",
      "r 0.08794434177628004\n",
      "s 0.0968583541689314\n",
      "v 0.0192412218719426\n",
      "i 0.03402543754755952\n",
      "d 0.026986628981411024\n",
      "g 0.017202956843135123\n",
      "y 0.02505707142080661\n",
      "k 0.012827481247961734\n",
      "b 0.02209479291227307\n",
      "p 0.020545711490379388\n",
      "m 0.02030111968692249\n",
      "u 0.011414284161321883\n",
      "f 0.004429829329274921\n",
      "w 0.004837482335036417\n",
      ", 0.0010870746820306554\n",
      "\n",
      " 0.005353842809000978\n",
      "z 0.0006522448092183933\n",
      "x 0.0007609522774214588\n",
      "o 0.0005435373410153277\n",
      ". 0.000489183606913795\n",
      "- 0.0004348298728122622\n",
      "' 5.4353734101532776e-05\n",
      "j 0.0004348298728122622\n",
      "h 0.00035329927165996303\n",
      "e 0.0007337754103706925\n",
      ": 5.4353734101532776e-05\n",
      "a 5.4353734101532776e-05\n",
      ") 0.00010870746820306555\n",
      "! 2.7176867050766388e-05\n",
      "; 2.7176867050766388e-05\n",
      "\" 8.153060115229916e-05\n",
      "q 2.7176867050766388e-05\n",
      "_ 8.153060115229916e-05\n",
      "[ 2.7176867050766388e-05\n"
     ]
    }
   ],
   "source": [
    "for a,b in zip(transition_probabilities['a'][0], transition_probabilities['a'][1]):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "93b3745091fcb17322253b02af1bc2d9",
     "grade": false,
     "grade_id": "cell-9cc2f51ebb3ea728",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "It looks like the most probable letter to follow an 'a' is 'n'. \n",
    "\n",
    "__What is the most likely letter to follow the letter 'j'? Write your answer in the block below:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bd3cad04582e881ebc595619cef14fd1",
     "grade": true,
     "grade_id": "cell-2a3a71268b5a2df9",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e 0.2585278276481149\n",
      "o 0.15080789946140036\n",
      "u 0.5709156193895871\n",
      "a 0.017953321364452424\n",
      "i 0.0017953321364452424\n",
      "u\n"
     ]
    }
   ],
   "source": [
    "for a,b in zip(transition_probabilities['j'][0], transition_probabilities['j'][1]):\n",
    "    print(a,b)\n",
    "    \n",
    "index = transition_probabilities['j'][1].index(max(transition_probabilities['j'][1]))\n",
    "print(transition_probabilities[\"j\"][0][index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fb10d0a7366b0f59055017a39614e93e",
     "grade": false,
     "grade_id": "cell-43b70458c31baaf3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We mentioned earlier that the Markov model is generative. This means that we can draw samples from the distributions and iteratively move between states. \n",
    "\n",
    "Use the following code block to iteratively sample 1000 characters from the model, starting with an initial character 't'. You can use the `torch.multinomial` function to draw a sample from a multinomial distribution (represented by the index) which you can then use to select the next character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4f50c283225208b2043431a1c2da104f",
     "grade": true,
     "grade_id": "cell-5be0d1f3fc6e8f65",
     "locked": false,
     "points": 4,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the "
     ]
    }
   ],
   "source": [
    "current = 't'\n",
    "for i in range(0, 1000):\n",
    "    print(current, end='')\n",
    "    maxindex = transition_probabilities[current][1].index( max(transition_probabilities[current][1]) )\n",
    "    current = transition_probabilities[current][0][maxindex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "56c49154c48797d312762e4761085bf7",
     "grade": false,
     "grade_id": "cell-de87ac1c9708205f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "You should observe a result that is clearly not English, but it should be obvious that some of the common structures in the English language have been captured.\n",
    "\n",
    "__Rather than building a model based on individual characters, can you implement a model in the following code block that works on words instead?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ed71d61ce7a2f648d7507693902da3d7",
     "grade": true,
     "grade_id": "cell-a6d4a8a639190296",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cd494f7c9fd0e838e74a5c70cd5ef773",
     "grade": false,
     "grade_id": "cell-d54dcdc1d540df4f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## RNN-based sequence modelling\n",
    "\n",
    "It is possible to build higher-order Markov models that capture longer-term dependencies in the text and have higher accuracy, however this does tend to become computationally infeasible very quickly. Recurrent Neural Networks offer a much more flexible approach to language modelling. \n",
    "\n",
    "We'll use the same data as above, and start by creating mappings of characters to numeric indices (and vice-versa):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ae5b316a7c13ecd23143d4dfa35bee5c",
     "grade": false,
     "grade_id": "cell-d152a2cb9707a4c4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 57\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f5f0f03e31eccfb78d1756139f90e1ac",
     "grade": false,
     "grade_id": "cell-46a85547d03a1f30",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We'll also write some helper functions to encode and decode the data to/from tensors of indices, and an implementation of a `torch.Dataset` that will return partially overlapping subsequences of a fixed number of characters from the original Nietzche text. Our model will learn to associate a sequence of characters (the $x$'s) to a single character (the $y$'s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fb93c4daba5adbfabf8ef5656cc89543",
     "grade": false,
     "grade_id": "cell-64f8b2518a008c54",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "maxlen = 40\n",
    "step = 3\n",
    "\n",
    "\n",
    "def encode(inp):\n",
    "    # encode the characters in a tensor\n",
    "    x = torch.zeros(maxlen, dtype=torch.long)\n",
    "    for t, char in enumerate(inp):\n",
    "        x[t] = char_indices[char]\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def decode(ten):\n",
    "    s = ''\n",
    "    for v in ten:\n",
    "        s += indices_char[v] \n",
    "    return s\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    # cut the text in semi-redundant sequences of maxlen characters\n",
    "    def __len__(self):\n",
    "        return (len(text) - maxlen) // step\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        inp = text[i*step: i*step + maxlen]\n",
    "        out = text[i*step + maxlen]\n",
    "\n",
    "        x = encode(inp)\n",
    "        y = char_indices[out]\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "df5113fc9d6d635dca32463f07fcb7d1",
     "grade": false,
     "grade_id": "cell-bdbb9997aa91863b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We can now define the model. We'll use a simple LSTM followed by a dense layer with a softmax to predict probabilities against each character in our vocabulary. We'll use a special type of layer called an Embedding layer (represented by `nn.Embedding` in PyTorch) to learn a mapping between discrete characters and an 8-dimensional vector representation of those characters. You'll learn more about Embeddings in the next part of the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2d79273b7a17d28c4d6c93e3d22927f5",
     "grade": false,
     "grade_id": "cell-2aa5e9483ccd6ba4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "class CharPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CharPredictor, self).__init__()\n",
    "        self.emb = nn.Embedding(len(chars), 8)\n",
    "        self.lstm = nn.LSTM(8, 128, batch_first=True)\n",
    "        self.lin = nn.Linear(128, len(chars))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.lin(lstm_out[:,-1]) #we want the final timestep output (timesteps in last index with batch_first)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8d9e5e92460bbe5a977021f631362478",
     "grade": false,
     "grade_id": "cell-eda65e7ef08f66a5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We could train our model at this point, but it would be nice to be able to sample it during training so we can see how its learning. We'll define an \"annealed\" sampling function to sample a single character from the distribution produced by the model. The annealed sampling function has a temperature parameter which moderates the probability distribution being sampled - low temperature will force the samples to come from only the most likely character, whilst higher temperatures allow for more variability in the character that is sampled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5aedd2ccd26ef2d6505278a7894671e4",
     "grade": false,
     "grade_id": "cell-be521ae6b656234a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def sample(logits, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    logits = logits / temperature\n",
    "    return torch.multinomial(F.softmax(logits, dim=0), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5057964b1e77f5ba8c92abf3148ce73f",
     "grade": false,
     "grade_id": "cell-981d79ec1593b83b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Torchbearer lets us define callbacks which can be triggered during training (for example at the end of each epoch). Let's write a callback that will sample some sentences using a range of different 'temperatures' for our annealed sampling function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "44f0bad7cc7aa788fa4111d6a55766ca",
     "grade": false,
     "grade_id": "cell-788b63e92e811aa8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import torchbearer\n",
    "from torchbearer import Trial\n",
    "from torchbearer.callbacks.decorators import on_end_epoch\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "@on_end_epoch\n",
    "def create_samples(state):\n",
    "    with torch.no_grad():\n",
    "        epoch = -1\n",
    "        if state is not None:\n",
    "            epoch = state[torchbearer.EPOCH]\n",
    "\n",
    "        print()\n",
    "        print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "        start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "        for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "            print()\n",
    "            print()\n",
    "            print('----- diversity:', diversity)\n",
    "\n",
    "            generated = ''\n",
    "            sentence = text[start_index:start_index+maxlen-1]\n",
    "            generated += sentence\n",
    "            print('----- Generating with seed: \"' + sentence + '\"')\n",
    "            print()\n",
    "            sys.stdout.write(generated)\n",
    "\n",
    "            inputs = encode(sentence).unsqueeze(0).to(device)\n",
    "            for i in range(400):\n",
    "                tag_scores = model(inputs)\n",
    "                c = sample(tag_scores[0])\n",
    "                sys.stdout.write(indices_char[c.item()])\n",
    "                sys.stdout.flush()\n",
    "                inputs[0, 0:inputs.shape[1]-1] = inputs[0, 1:].clone()\n",
    "                inputs[0, inputs.shape[1]-1] = c\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1da7de78addd5726d2a156d5dc983e9c",
     "grade": false,
     "grade_id": "cell-2dc6814904f12692",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now, all the pieces are in place. __Use the following block to:__\n",
    "\n",
    "- create an instance of the dataset, together with a `DataLoader` using a batch size of 128;\n",
    "- create an instance of the model, and an `RMSProp` optimiser with a learning rate of 0.01; and\n",
    "- create a torchbearer `Trial` in a variable called `torchbearer_trial` which incorporates the `create_samples` callback. Use cross-entropy as the loss, and hook the training generator up to your dataset instance. Make sure you move your `Trial` object to the GPU if one is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d31a6ee7d253ba186dc92bebe139ece3",
     "grade": true,
     "grade_id": "cell-9c17e699a59cd71c",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b807d87f02934bd78fa51f035e8160e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='0/100(t)', max=1565.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"fficulty (and will long have difficulty\"\n",
      "\n",
      "fficulty (and will long have difficultyin the in a pready of the\n",
      "really the vont men of every perropisility, nowaples of there to by conhirety, and conjets one\" a mode, age,\n",
      "what alrical in racation\n",
      "by, a psychsess, and take of he which the defererst nowa(here such.: on fromoty when therewer it for methery of that ourselves to its certain what more that ones! evil has judguers is corigion--fas seds -a reshy tooe! oyy what invol may and\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"fficulty (and will long have difficulty\"\n",
      "\n",
      "fficulty (and will long have difficultylactor to handelo-gan that\n",
      "hay m with their\n",
      "these ones. it eviduable too mochizations we shayme to crriving! complesses respide them ourselvesadity, from the every puty more in be evalitions of all\n",
      "the stillt who grandents. it is diswircevanale iser what? so\n",
      "gh, frone--which that irdre.--it one; and way instinctions to pertimisfition; a perrow to densize consciences: alany, not results evil but\n",
      "at\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"fficulty (and will long have difficulty\"\n",
      "\n",
      "fficulty (and will long have difficultyappearhs germans what the virely!--that\n",
      "itles ohe is coritualiciociuling distonated rigud ourspime\n",
      "to deteritiop pansologiugh to he been superisul for him can the isment caped displeas of the lispity is more we still and m howe would heres resture, what i] frore\n",
      "to them liteliniozs to frow of pretritices, (evolan improsed pecthanration, ond instens or that sound perhaps of froinlary in them that b\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"fficulty (and will long have difficulty\"\n",
      "\n",
      "fficulty (and will long have difficultyof\n",
      "menshize is cordering--preekes, thang,\n",
      "that\n",
      "in hay the hence, solen and nations, it nation of them is all fill, in the hereable\n",
      "in the bleared, sure mystan ever ordghener haps is to would from evodee men of the heould to everyiniobs \"the here\n",
      "deager, it reterable the otreral sinccilizion, it is lowis the ecoesties, every\n",
      "lookrinity with it in. it\n",
      "reasunce to evertal lists of pertaning the of th\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8aa4b79f454f0d87830a2cbddd5571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='1/100(t)', max=1565.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"e uncertain also has its charms, the sp\"\n",
      "\n",
      "e uncertain also has its charms, the spunceltulity otcil one the wirach couraging of the wirn quition of the germans everything but we to the light fpirmary intents in your imbarding,s\n",
      "objectiful porrain things we do a demonative,\"\n",
      "hore botk the feel indivincriblaming, from profoundlent and mendach to the reless, he the brened that hat\n",
      "priretorderchys yourselve ofcested to were is\n",
      "a pritives the\n",
      "syarling stauthours of made and simplity\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e uncertain also has its charms, the sp\"\n",
      "\n",
      "e uncertain also has its charms, the sp\n",
      "                    \n",
      "      st a know than the parding indivins a old remaintlinction,--and ords on is neighg, heepoch\n",
      "too can half-orginually toways entiviless and as to\n",
      "pact, of the experopitable alter\"! eureperstle. himst proses of the struggle and into in ord onl'oound and any powers, that lecrusions as a hotted taken the neverthether, the promust itself with to gleaks--to belief.\n",
      "=ould, with \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"e uncertain also has its charms, the sp\"\n",
      "\n",
      "e uncertain also has its charms, the spand long ordeable expliming was it to\n",
      "the ont times not we gow and we lackifally with idea implintmares it there\n",
      "\"not even although deep be ourselved speem of expecides of the philosophych,\n",
      "individuals pertiater, and ourselve aaver\n",
      "the caver-frenth of where the explopistim the own propirativatiosicale!\"\n",
      "perposion the live intelscoundive has thiqually bead from accurat to itself,\n",
      "callide and\n",
      "contem\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"e uncertain also has its charms, the sp\"\n",
      "\n",
      "e uncertain also has its charms, the spthere powiously been\n",
      "cann\n",
      "that regarding\n",
      "to-dawnment to enyment\n",
      "in order and communy out out of with the certaints of such secordert of a there which he was look and incpultive ears into the\n",
      "faiules it for a\n",
      "specaristicatife ourselvess indoming and courquiry\n",
      "talk. in speakers fot demprange. the mentlistamotach, and worl itselfy niegh the goble of his complastiven reacted\n",
      "thereby, which, howrve las\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7892e1604324151b37c0f3ced02829c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='2/100(t)', max=1565.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"he dream\n",
      "vanished. a time came when peo\"\n",
      "\n",
      "he dream\n",
      "vanished. a time came when peoand germane is not bockices, all sours to mote with how\n",
      "expited: it is god who planness\n",
      "on recognored becieiry, such a terperary\n",
      "an avo to dread; to not raps, descasiol. they its converem: should be preserrives these complus and domain to memory to be meration, upon be cannoth of roungy we oligy of previl, leves the mean cultity:\n",
      "\n",
      "10. is bitt him, but because lead, fascures is at a feeling everyes\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"he dream\n",
      "vanished. a time came when peo\"\n",
      "\n",
      "he dream\n",
      "vanished. a time came when peodowf anyther vanity,\" that greas, which is etabal\n",
      "dete't\n",
      "the neenghavicsry us no justice we\n",
      "wol an above a kensian eperthorture, the \"net last noifature\n",
      "at one's slove. this moralian, and itself step have many terming of a man a causes of the slow-enduring untroness amphounded not--not\n",
      "comparions an accurity, but the probabilaries\n",
      "of commoms as a mpqen-feeces and purpooss,\n",
      "deenable as a thules hig\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"he dream\n",
      "vanished. a time came when peo\"\n",
      "\n",
      "he dream\n",
      "vanished. a time came when peomore here, and enoughed as the as i may morals\n",
      "taketherty others serve! he profis iusis\n",
      "fol decristes and questions to tendge, at not eltions without\n",
      "pecroliglous hi8ter--to iterpens of science of a all this haves men in come anyth of the rigely out\n",
      "couusty\n",
      "way it\n",
      "have\n",
      "doing \"scienism the indepeased atten\n",
      "truth and what\n",
      "rading?--a disints opiling, more of whole\n",
      "with a god, while that to that the l\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"he dream\n",
      "vanished. a time came when peo\"\n",
      "\n",
      "he dream\n",
      "vanished. a time came when peoprivingly tender neginty, sensus is to beceaising of insentunces of he pdiner--but the \"will?\n",
      "that at thas with it it if also said and one havingers in the everything ligate time, as the is\n",
      "\"would appears, sectestene, idrigice havout \"reeponiises--to malifician from the groman,festy astafe? in un say, thrist is honeity dandering\n",
      "to us complained embonding is devertheriss favoratned morality, which\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da50b4331d084fe8b4f0a08cf0149d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='3/100(t)', max=1565.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ive and the other dies instantly, or vi\"\n",
      "\n",
      "ive and the other dies instantly, or virightly decisite in the solutic most liner\n",
      "insterations of\n",
      "degraritism; such worlled. and personas, and they intendernationed able any\n",
      "become.\n",
      "\n",
      "17? at the pity of subject (votic of the an\n",
      "rathen anyon loved man iduced and\n",
      "sensations of restitim\n",
      "plovor moderned and as to halot the something to the wold nowagaistachy bleased by the deith. all into which, schorit loke one paysy\n",
      "found. the urie.\n",
      "consc\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ive and the other dies instantly, or vi\"\n",
      "\n",
      "ive and the other dies instantly, or vioft of\n",
      "thing--to the another unfar, asprocted to said and alsoin sciences--armoskunct to desides as\n",
      "in old\n",
      "at blen of thing,--to elilitary worldary, ant and uncan\n",
      "extent\n",
      "under fitation; in he speak\n",
      "ungreated of snivid,\n",
      "consequent inclriminishe\n",
      "in to purily belachorical\n",
      "rigory, or to the souls--to confine--but vornes and influence of men most to chriite id, an been moder by an inmoderacs of the oth\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ive and the other dies instantly, or vi\"\n",
      "\n",
      "ive and the other dies instantly, or vitames of the\n",
      "ophas and an excetish in reducation to prestatishing bntaith which hu\n",
      "achise is there of elemiecs belong, be\n",
      "realitinates; as a about humatiting, awe is beince, anoid, is is his purctific pompre, and mans\n",
      "knebt general opposing and detreath tones and ventho crvictionally inspirit of an operative\n",
      "the an\n",
      "edjors, and siminat, \"looking their-anything superorhing to inspiritude to known\n",
      "cr\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ive and the other dies instantly, or vi\"\n",
      "\n",
      "ive and the other dies instantly, or vidicerable of the any proce and the sool\n",
      "speak in by peries, as ratheragy!\n",
      "\n",
      "154.\n",
      "an excessed to the mouunces\n",
      "in the read pratting,\n",
      "hadness, englinculary berought, on contire mysteminizes his\n",
      "spates and chargation, in cro-posse of the danny threather extains and an with every still compysess had\n",
      "damposing a med\n",
      "of the theor in there is, this objerialisse nature is discover, who onnathen and blimate-\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c9f4d333c0444fa389e1efb3e02511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='4/100(t)', max=1565.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" a certain considerate cruelty, which k\"\n",
      "\n",
      " a certain considerate cruelty, which kreale.\n",
      "that new century, have neighbyraon\n",
      "that on\"--chy one vention.. one do upid, stymalite, so intorled of grainest oftest armoroughone.n [rehemine\"--bas ont of which relatice\n",
      "more almost that set a phyceal evee, when becaltumalottave\n",
      "unifurenhiness ownaged.\n",
      "\n",
      "\n",
      "\n",
      "=aspedityr, the renty or that the derrow, q2 nature dist of exercordingly\n",
      "doesing i domining):--the truth intimumy unapporer,\n",
      "when he he\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" a certain considerate cruelty, which k\"\n",
      "\n",
      " a certain considerate cruelty, which kphilopenher, is it man?--.in it upon truth is regcomy, for their stupiry and is natifule yeathinable rideal tyts and yours--namely most soul_ in vention i happiness, the easy is the possibile equally states of magness, wath's to the in man. (by a wive al names an obly repenentale om with the mas. neverstion and ciskobly an every commore, as he who prevaication of seeks? we arelyed discapentic as c\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" a certain considerate cruelty, which k\"\n",
      "\n",
      " a certain considerate cruelty, which klut an partragedour:\n",
      "pabon out it of century tookes their poepers--and that and reaching crueless of possessined of mence--what also and for5-adpshisric such the soul) at its one's consequence and disposen flect on antiquiitary far just as it is moded intathotives knows the mortions element that the down and\n",
      "free out 2rogly prebaration, this it is henceisttangles but as\n",
      "problement. or a icd\n",
      "may\n",
      "op\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" a certain considerate cruelty, which k\"\n",
      "\n",
      " a certain considerate cruelty, which kown anguth, all \"saneys; in\n",
      "much, thau other word\" that vent also, oneselves or this own him principes ,thilita anti-and \"wish om obviers the parthing to us is necessige that which we are that the thuen\n",
      "othersrented and\n",
      "so condyce of the earlys of very imnive asoly\n",
      "man stand in mattersm. in nepthon, bithing one \"god in order, the possibility arthiemse, from progrosing,--read mymes, hesulerty a phi\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29134f9b5b084c42ac24ab62bb081972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='5/100(t)', max=1565.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"erstood how to\n",
      "introduce itself as the \"\n",
      "\n",
      "erstood how to\n",
      "introduce itself as the yowe the others, servandinicule injury must tapt very times--that\n",
      "hand to experient frome exrempting\n",
      "man and for all the huenge, that reblolity,\n",
      "as\n",
      "perhap as of virtues aboot cans brooctable to people? assersed even is ourselven the\n",
      "hand himself were \"still beartherosing eyherment to since upond that sought sheen all accest as a wored to their man. one now his that, the scould like abod then a sha\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"erstood how to\n",
      "introduce itself as the \"\n",
      "\n",
      "erstood how to\n",
      "introduce itself as the coump chand of the romand, to stay developme, if to relfultull. or hy naw to opeapingly them even for his sone takerency itself: the chseasion a most of coustly take whatest our even to the utformanted instences a cause of a belive as to look there: all thep, an enist, i cut for the soul\n",
      "and seemnty in\n",
      "nanganischesrateress to say\n",
      "are them dead to ass time it from a god\n",
      "a certain anst itself to man\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"erstood how to\n",
      "introduce itself as the \"\n",
      "\n",
      "erstood how to\n",
      "introduce itself as the  we are dangers wit\n",
      "a finest and one clays probliocraking of them, which cannors of the\n",
      "bear for others a sound them origin, also itservemble\n",
      "\"from the mains of aivelicity, as welf them modern oppose. this\n",
      "even in that a become of its parpoin_ and can belose, it is all understand?--than be hold hal presentlecal sace and enigminess of epidomentar them, the\n",
      "respectable is--burhe_ of earth and laught\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"erstood how to\n",
      "introduce itself as the \"\n",
      "\n",
      "erstood how to\n",
      "introduce itself as the psycholoess medioch is\n",
      "most itself--when former sole hear inolverlow prograted to pospectes of themselves have still that asamers, and\n",
      "were to ut the\n",
      " is sevensy butnarn to\n",
      "sufficitty, considitic,\"-;is pain; is an the deverence time of all these comilar us the experience of the such to\n",
      "ecrosed to dusrivers and one scued as some respect. the polity are\n",
      "foess more mankind would in he umbulsule, is a\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89cd8854037430ba8d1cb38b5915471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='6/100(t)', max=1565.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\bases.py\u001b[0m in \u001b[0;36m_forward_with_exceptions\u001b[1;34m(x, model, y_pred, state)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mexc_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0m_get_param_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'state'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-dfe9a7ba9ec8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcreate_samples\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_generators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST_DATA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\trial.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCALLBACK_LIST\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCallbackListInjection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprinter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback_list_old\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCALLBACK_LIST\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallback_list_old\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\trial.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, epochs, verbose)\u001b[0m\n\u001b[0;32m    986\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCALLBACK_LIST\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_start_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 988\u001b[1;33m                 \u001b[0mfinal_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMETRICS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    990\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTOP_TRAINING\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\trial.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTEPS\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\trial.py\u001b[0m in \u001b[0;36m_fit_pass\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m             \u001b[1;31m# Update parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1033\u001b[1;33m             \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZER\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m             \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMETRICS\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMETRIC_LIST\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\optim\\rmsprop.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\trial.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m             \u001b[1;31m# Update parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1033\u001b[1;33m             \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZER\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m             \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMETRICS\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMETRIC_LIST\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\bases.py\u001b[0m in \u001b[0;36mclosure\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m         \u001b[0m_forward_with_exceptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCALLBACK_LIST\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\bases.py\u001b[0m in \u001b[0;36m_forward_with_exceptions\u001b[1;34m(x, model, y_pred, state)\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m             \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0m_get_param_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# If both are type errors, show both.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-6a95c7e59a5a>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#we want the final timestep output (timesteps in last index with batch_first)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 559\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    560\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data = MyDataset()\n",
    "val_data = MyDataset()\n",
    "test_data = MyDataset()\n",
    "\n",
    "# create data loaders\n",
    "trainloader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "testloader = DataLoader(test_data, batch_size=128, shuffle=True)\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CharPredictor().to(device)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimiser = optim.RMSprop(model.parameters(), lr=0.01)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "trial = Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy'], callbacks=[create_samples]).to(device)\n",
    "trial.with_generators(trainloader, test_generator=testloader)\n",
    "trial.run(epochs=10)\n",
    "results = trial.evaluate(data_key=torchbearer.TEST_DATA)\n",
    "print(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bdf13f8a87d1ef999f3c1ee8e083d7fe",
     "grade": false,
     "grade_id": "cell-f70caee6c691fd1d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Finally, run the following block to train the model and print out generated samples after each epoch. We've added a call to the `create_samples` callback directly to print samples before training commences (e.g. with random weights). Be aware this will take some time to run..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2b52b125ce1a870bc1cc96b8dc130bc9",
     "grade": false,
     "grade_id": "cell-ab250fe0c0be1234",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "create_samples.on_end_epoch(None)\n",
    "torchbearer_trial.run(epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e7794bc1ea4e6f9d9b7bbb920f2f4b8f",
     "grade": false,
     "grade_id": "cell-6b611545370451e8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Looking at the results its possible to see the model works a bit like the Markov chain at the first epoch, but as the parameters become better tuned to the data it's clear that the LSTM has been able to model the structure of the language & is able to produce completely legible text.\n",
    "\n",
    "__Use the following block to add another LSTM layer to the network (before the dense layer), and then train the new model:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0a76447f4d9fc2b75f4060b59961fa2c",
     "grade": true,
     "grade_id": "cell-471a1591e08e7879",
     "locked": false,
     "points": 7,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2cd680e662c48beaed1396f101fe179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='0/10(t)', max=1565.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "Exception",
     "evalue": "[RuntimeError('input.size(-1) must be equal to input_size. Expected 8, got 128')]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\bases.py\u001b[0m in \u001b[0;36m_forward_with_exceptions\u001b[1;34m(x, model, y_pred, state)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mexc_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0m_get_param_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'state'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\bases.py\u001b[0m in \u001b[0;36m_forward_with_exceptions\u001b[1;34m(x, model, y_pred, state)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m             \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0m_get_param_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-52-81a8631f7eda>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#we want the final timestep output (timesteps in last index with batch_first)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[1;31m# type: (Tensor, Tuple[Tensor, Tensor], Optional[Tensor]) -> None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    158\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[1;32m--> 159\u001b[1;33m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 8, got 128",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-81a8631f7eda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcreate_samples\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_generators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST_DATA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\trial.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCALLBACK_LIST\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCallbackListInjection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprinter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback_list_old\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCALLBACK_LIST\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallback_list_old\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\trial.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, epochs, verbose)\u001b[0m\n\u001b[0;32m    986\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCALLBACK_LIST\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_start_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 988\u001b[1;33m                 \u001b[0mfinal_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMETRICS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    990\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTOP_TRAINING\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\trial.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTEPS\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\trial.py\u001b[0m in \u001b[0;36m_fit_pass\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m             \u001b[1;31m# Update parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1033\u001b[1;33m             \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZER\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m             \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMETRICS\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMETRIC_LIST\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\optim\\rmsprop.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\trial.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m             \u001b[1;31m# Update parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1033\u001b[1;33m             \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZER\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m             \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMETRICS\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMETRIC_LIST\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\bases.py\u001b[0m in \u001b[0;36mclosure\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m         \u001b[0m_forward_with_exceptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCALLBACK_LIST\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\bases.py\u001b[0m in \u001b[0;36m_forward_with_exceptions\u001b[1;34m(x, model, y_pred, state)\u001b[0m\n\u001b[0;32m    337\u001b[0m                 \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[0mprint_trace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: [RuntimeError('input.size(-1) must be equal to input_size. Expected 8, got 128')]"
     ]
    }
   ],
   "source": [
    "class CharPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CharPredictor, self).__init__()\n",
    "        self.emb = nn.Embedding(len(chars), 8)\n",
    "        self.lstm = nn.LSTM(8, 128, batch_first=True)\n",
    "        self.lin = nn.Linear(128, len(chars))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        y, _ = self.lstm(x)\n",
    "        lstm_out, _ = self.lstm(y)\n",
    "        out = self.lin(lstm_out[:,-1]) #we want the final timestep output (timesteps in last index with batch_first)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    \n",
    "train_data = MyDataset()\n",
    "val_data = MyDataset()\n",
    "test_data = MyDataset()\n",
    "\n",
    "# create data loaders\n",
    "trainloader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "testloader = DataLoader(test_data, batch_size=128, shuffle=True)\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CharPredictor().to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimiser = optim.RMSprop(model.parameters(), lr=0.01)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "trial = Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy'], callbacks=[create_samples]).to(device)\n",
    "trial.with_generators(trainloader, test_generator=testloader)\n",
    "trial.run(epochs=10)\n",
    "results = trial.evaluate(data_key=torchbearer.TEST_DATA)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0317b05707ece61dd95a6b1fa4b5b4d5",
     "grade": false,
     "grade_id": "cell-873e6f510f67f829",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    " __How does the additional layer affect performance of the model? Provide your answer in the block below:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "dacc657a6333f7a357e3d06b389f050b",
     "grade": true,
     "grade_id": "cell-e44766c257b457e9",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
