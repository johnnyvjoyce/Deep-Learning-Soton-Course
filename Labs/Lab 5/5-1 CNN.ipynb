{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0386b88759cd8dda9c6211fc1ef856a5",
     "grade": false,
     "grade_id": "cell-4b3a34920f4c7395",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 1: Training and evaluating simple CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a06e331b63eb9f8b5511ee8e90ae3dc6",
     "grade": false,
     "grade_id": "cell-2852eef932feefd7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "__Before starting, we recommend you enable GPU acceleration if you're running on Colab.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "84a38ee23b261ec917497a78bd147d1f",
     "grade": false,
     "grade_id": "cell-6f99954a67e07cc3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Execute this code block to install dependencies when running on colab\n",
    "try:\n",
    "    import torch\n",
    "except:\n",
    "    from os.path import exists\n",
    "    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "    cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "    accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "    !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl torchvision\n",
    "\n",
    "try: \n",
    "    import torchbearer\n",
    "except:\n",
    "    !pip install torchbearer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ce847410c1ef0a28d490008cedf86b4a",
     "grade": false,
     "grade_id": "cell-d0369c9de7c5a89e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Simple Convolutional Neural Network for MNIST\n",
    "\n",
    "Now that we have seen how to load the MNIST dataset and train a simple multi-layer perceptron model on it, we can now start to develop a more sophisticated convolutional neural network or CNN model. PyTorch provides a lot of capability for creating CNNs, and includes a large number of layer types and activation functions. In this part of the lab we will create a simple CNN for MNIST that demonstrates how to use all of the aspects of a modern CNN implementation, including Convolutional layers, Pooling layers and Dropout layers.\n",
    "\n",
    "The first step is to import the classes and functions needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "175dd97d30f646eb74ad9e21427a2c0d",
     "grade": false,
     "grade_id": "cell-b7a634722fea19b2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# automatically reload external modules if they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchbearer\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchbearer import Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dbd5411f763365d82fece69745457168",
     "grade": false,
     "grade_id": "cell-36d240a1fee1f6f2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Again, initialise the random number generator to a constant seed value for reproducibility of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b422e04bbefbf78800d34b845c1397d5",
     "grade": false,
     "grade_id": "cell-4d617d7c9adb1794",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1caef4794d2c1a7d0a0ca69b5c8c3669",
     "grade": false,
     "grade_id": "cell-f5f854670ab50aed",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Next we need to load the MNIST dataset. Unlike with the MLP example we looked at previously, we don't want to flatten the images into vectors, although we do still want to convert the PIL images to tensors.\n",
    "\n",
    "In PyTorch, images are represented as tensors with dimensions `[pixels][height][width]`. In the case of RGB, the first dimension, pixels, would be 3 for the red, green and blue components. In the case of MNIST where the pixel values are greyscale, the pixel dimension is set to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "29254ea7761e47b036e1bf7e6e6f8f00",
     "grade": false,
     "grade_id": "cell-fe9cacfcc16dcddf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# convert each image to tensor format\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # convert to tensor\n",
    "])\n",
    "\n",
    "# load data\n",
    "trainset = MNIST(\".\", train=True, download=True, transform=transform)\n",
    "testset = MNIST(\".\", train=False, download=True, transform=transform)\n",
    "\n",
    "# create data loaders\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "aa79db913111d98503bf94cc0f4c77a8",
     "grade": false,
     "grade_id": "cell-f094c93f38605686",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Next we define our neural network model.\n",
    "\n",
    "Convolutional neural networks are more complex than standard multi-layer perceptrons, so we will start by using a simple structure to begin with that uses all of the elements required for near state of the art results. The network architecture is summarised below:\n",
    "\n",
    "1. The first hidden layer is a convolutional layer called a `Convolution2D`. The layer has 32 feature maps, which with the size of 5×5 and a rectified linear unit activation function.\n",
    "2. Next we define a pooling layer that takes the max called `MaxPooling2D`. It is configured with a pool size of 2×2.\n",
    "3. The next layer is a regularization layer using dropout called `Dropout`. It is configured to randomly exclude 20% of neurons in the layer in order to reduce overfitting.\n",
    "4. Next is an operation that flattens or reshapes the tensor to a vector. It allows the output to be processed by standard fully connected layers.\n",
    "5. Next a fully connected layer with 128 neurons and rectifier linear unit activation function.\n",
    "6. Finally, the output layer has 10 neurons for the 10 classes.\n",
    "\n",
    "Just like with the MLP we create a PyTorch `nn.Module` subclass to define our network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d978becfd60240a69ccfcb346d9fabdb",
     "grade": false,
     "grade_id": "cell-e36a90ba5353bd77",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, (5, 5), padding=0)\n",
    "        self.fc1 = nn.Linear(32 * 12**2, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, (2,2))\n",
    "        out = F.dropout(out, 0.2)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "80b333944df484312ce0c3804eca5e6b",
     "grade": false,
     "grade_id": "cell-7483d476ef9f0de6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Note in the above code when we use the `view` method to _flatten_ the tensor we must preserve the batch dimension of the data; passing `-1` as the second argument tells view to compute the size of the dimension represented by the `-1` automatically. The input to the forward method has shape `[batch_size][pixels][height][width]` and we want the final output to be `[batch_size][num_classes=10]`. \n",
    "\n",
    "__Answer the following questions (enter the answer in the box below each one):__\n",
    "\n",
    "__1.__ What is the shape of the tensor output by the `conv1` layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a8e7f96c4270925d62470b6875acaa0d",
     "grade": true,
     "grade_id": "cell-85c7d9e142f0f5a8",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "(32-5)+1 = 28\n",
    "\n",
    "28\\*28\\*32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9ba2f36afc0dd997780d17b4d9ce5e04",
     "grade": false,
     "grade_id": "cell-423f347f09d8ecd9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "__2.__ If the `conv1` layer had a kernel shape of `(7,3)` what would the output shape be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5c8923855a9c4f95ffbd658bfaf8201a",
     "grade": true,
     "grade_id": "cell-5bded1643d1a5530",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e690b390d913ddf3d089a55a8c9b9887",
     "grade": false,
     "grade_id": "cell-369d69d982d860ef",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "As before, the model is trained using cross-entropy loss and the ADAM gradient descent algorithm. The CNN is fit over 10 epochs with a batch size of 128. We use torchbearer to minimise the training and evaluation code we need to write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "666b5f1daf8391d5c1a1ab426caddf90",
     "grade": false,
     "grade_id": "cell-03a034a2e45728dd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3fa4c5c6b54c779949280744c8f54c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='0/10(t)', max=469.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c5682775204145a635a5b5030dfdf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='1/10(t)', max=469.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe66ae6dc649419ea240faad25680b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='2/10(t)', max=469.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf7357b46494db8a7eef24e13c01d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='3/10(t)', max=469.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542792fe54114e5290cae676ada7ccf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='4/10(t)', max=469.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5781bf5e8794e0e9e9a7f88848f3539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='5/10(t)', max=469.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2daab98a3cf4179a3654707324663d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='6/10(t)', max=469.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791984518699442bab292ee93bb33080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='7/10(t)', max=469.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c83f1cb5c9465181f4a3add696b76f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='8/10(t)', max=469.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28fc34a844348e2b19c85654fb8370b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='9/10(t)', max=469.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00dc9d0ca060456895e7e4beb8d66b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='0/1(e)', max=79.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'test_loss': 0.038808271288871765, 'test_acc': 0.9884999990463257}\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# define the loss function and the optimiser\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimiser = optim.Adam(model.parameters())\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "trial = Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)\n",
    "trial.with_generators(trainloader, test_generator=testloader)\n",
    "trial.run(epochs=10)\n",
    "results = trial.evaluate(data_key=torchbearer.TEST_DATA)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "671150370dacaaf1a06bf5c07f288cbf",
     "grade": false,
     "grade_id": "cell-b839b934e04f89c0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "You should see that the network achieves an accuracy of 98.91% which is better than the simple multi-layer perceptron model we tried previously.\n",
    "\n",
    "## An improved CNN\n",
    "\n",
    "Now that we have seen how to create a simple CNN, let’s take a look at a model capable of close to state of the art results. This time you will implement a large CNN architecture with additional convolutional, max pooling layers and fully connected layers. The network topology of the model is summarised as follows:\n",
    "\n",
    "1. Convolutional layer with 30 feature maps of size 5×5 and ReLU activation.\n",
    "2. Pooling layer taking the max over 2×2 patches.\n",
    "3. Convolutional layer with 15 feature maps of size 3×3 and ReLU activation.\n",
    "4. Pooling layer taking the max over 2×2 patches.\n",
    "5. Dropout layer with a probability of 20%.\n",
    "6. Flatten layer.\n",
    "7. Fully connected layer with 128 neurons and ReLU activation.\n",
    "8. Fully connected layer with 50 neurons and ReLU activation.\n",
    "9. Linear output layer.\n",
    "\n",
    "__Complete the implementation of the BetterCNN module which implements the above network in the following code block.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3a544d1f48cb9b1af278acbebdf391be",
     "grade": false,
     "grade_id": "cell-110a1189124033d9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe first hidden layer is a convolutional layer called a Convolution2D. The layer has 32 feature maps, which with the size of 5×5 and a rectified linear unit activation function.\\nNext we define a pooling layer that takes the max called MaxPooling2D. It is configured with a pool size of 2×2.\\nThe next layer is a regularization layer using dropout called Dropout. It is configured to randomly exclude 20% of neurons in the layer in order to reduce overfitting.\\nNext is an operation that flattens or reshapes the tensor to a vector. It allows the output to be processed by standard fully connected layers.\\nNext a fully connected layer with 128 neurons and rectifier linear unit activation function.\\nFinally, the output layer has 10 neurons for the 10 classes.\\n\\nclass SimpleCNN(nn.Module):\\n    def __init__(self):\\n        super(SimpleCNN, self).__init__()\\n        self.conv1 = nn.Conv2d(1, 32, (5, 5), padding=0)\\n        self.fc1 = nn.Linear(32 * 12**2, 128)\\n        self.fc2 = nn.Linear(128, 10)\\n            \\n    def forward(self, x):\\n        out = self.conv1(x)\\n        out = F.relu(out)\\n        out = F.max_pool2d(out, (2,2))\\n        out = F.dropout(out, 0.2)\\n        out = out.view(out.shape[0], -1)\\n        out = self.fc1(out)\\n        out = F.relu(out)\\n        out = self.fc2(out)\\n        return out\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "# Model Definition\n",
    "class BetterCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BetterCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 30, (5, 5), padding=0)\n",
    "        self.conv2 = nn.Conv2d(30, 15, (3, 3), padding=0)\n",
    "        self.fc1 = nn.Linear(15 * 5**2, 128)\n",
    "        self.fc2 = nn.Linear(128, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, (2,2))\n",
    "        out = self.conv2(out)\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, (2,2))\n",
    "        out = F.dropout(out, 0.2)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "        \n",
    "'''\n",
    "\n",
    "The first hidden layer is a convolutional layer called a Convolution2D. The layer has 32 feature maps, which with the size of 5×5 and a rectified linear unit activation function.\n",
    "Next we define a pooling layer that takes the max called MaxPooling2D. It is configured with a pool size of 2×2.\n",
    "The next layer is a regularization layer using dropout called Dropout. It is configured to randomly exclude 20% of neurons in the layer in order to reduce overfitting.\n",
    "Next is an operation that flattens or reshapes the tensor to a vector. It allows the output to be processed by standard fully connected layers.\n",
    "Next a fully connected layer with 128 neurons and rectifier linear unit activation function.\n",
    "Finally, the output layer has 10 neurons for the 10 classes.\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, (5, 5), padding=0)\n",
    "        self.fc1 = nn.Linear(32 * 12**2, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, (2,2))\n",
    "        out = F.dropout(out, 0.2)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9fa81f5c9c2759a8b1fbc372028497c3",
     "grade": false,
     "grade_id": "cell-ad9d70fbb2d8fc5f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Once you've completed the implementation, save the file and run the following code block to train and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5cf30cdbb30e88f01a91f8eebfc8246c",
     "grade": true,
     "grade_id": "cell-da90b81391df00b2",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30fa68c49184dda84a345ea1a6b1581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='0/10(t)', max=469.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0565,  0.0212, -0.0290,  ..., -0.1092, -0.1373,  0.1049],\n",
      "        [-0.0470,  0.0353, -0.0351,  ..., -0.0894, -0.1206,  0.1036],\n",
      "        [-0.0427,  0.0299, -0.0086,  ..., -0.1085, -0.1178,  0.0985],\n",
      "        ...,\n",
      "        [-0.0616,  0.0234, -0.0187,  ..., -0.0976, -0.1252,  0.1134],\n",
      "        [-0.0407,  0.0283, -0.0446,  ..., -0.0869, -0.1278,  0.1033],\n",
      "        [-0.0624,  0.0217, -0.0130,  ..., -0.0929, -0.0968,  0.0940]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0571,  0.0107, -0.0018,  ..., -0.1065, -0.1077,  0.0895],\n",
      "        [-0.0536,  0.0205,  0.0056,  ..., -0.1098, -0.1133,  0.0753],\n",
      "        [-0.0650,  0.0059,  0.0190,  ..., -0.1114, -0.0937,  0.0739],\n",
      "        ...,\n",
      "        [-0.0482,  0.0121,  0.0108,  ..., -0.1241, -0.1066,  0.0900],\n",
      "        [-0.0601,  0.0081, -0.0031,  ..., -0.1022, -0.0904,  0.0877],\n",
      "        [-0.0548,  0.0083,  0.0049,  ..., -0.1052, -0.1033,  0.0947]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0741,  0.0030,  0.0098,  ..., -0.0675, -0.0500,  0.0624],\n",
      "        [-0.0623,  0.0039,  0.0080,  ..., -0.1067, -0.0772,  0.0629],\n",
      "        [-0.0626,  0.0137,  0.0126,  ..., -0.1075, -0.0598,  0.0738],\n",
      "        ...,\n",
      "        [-0.0700, -0.0016, -0.0107,  ..., -0.0826, -0.0814,  0.0663],\n",
      "        [-0.0711,  0.0054,  0.0346,  ..., -0.1007, -0.0792,  0.0479],\n",
      "        [-0.0597, -0.0111,  0.0200,  ..., -0.0900, -0.0862,  0.0576]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0859,  0.0201,  0.0023,  ..., -0.0886, -0.0495,  0.0620],\n",
      "        [-0.0652, -0.0257, -0.0066,  ..., -0.0694, -0.0230,  0.0652],\n",
      "        [-0.0821,  0.0055,  0.0124,  ..., -0.0702, -0.0224,  0.0698],\n",
      "        ...,\n",
      "        [-0.0837,  0.0084,  0.0130,  ..., -0.0823, -0.0297,  0.0538],\n",
      "        [-0.0826,  0.0031,  0.0094,  ..., -0.0716, -0.0276,  0.0613],\n",
      "        [-0.0764,  0.0097,  0.0096,  ..., -0.0804, -0.0243,  0.0605]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0762, -0.0077,  0.0057,  ..., -0.0485,  0.0003,  0.0576],\n",
      "        [-0.0885, -0.0111,  0.0264,  ..., -0.0680,  0.0112,  0.0451],\n",
      "        [-0.0929,  0.0191,  0.0148,  ..., -0.0781,  0.0101,  0.0511],\n",
      "        ...,\n",
      "        [-0.0594, -0.0208,  0.0175,  ..., -0.0819,  0.0054,  0.0453],\n",
      "        [-0.0904,  0.0264,  0.0047,  ..., -0.0589,  0.0161,  0.0384],\n",
      "        [-0.0823, -0.0227, -0.0034,  ..., -0.0325,  0.0073,  0.0676]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0708, -0.0221,  0.0021,  ..., -0.0368,  0.0350,  0.0356],\n",
      "        [-0.0665, -0.0225, -0.0007,  ..., -0.0262,  0.0395,  0.0363],\n",
      "        [-0.0519, -0.0184, -0.0034,  ..., -0.0630, -0.0025,  0.0397],\n",
      "        ...,\n",
      "        [-0.0849,  0.0050,  0.0157,  ..., -0.0463,  0.0568,  0.0368],\n",
      "        [-0.0365, -0.0341,  0.0033,  ..., -0.0681,  0.0026,  0.0627],\n",
      "        [-0.0984, -0.0041,  0.0078,  ..., -0.0422,  0.0139,  0.0676]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0693, -0.0404,  0.0325,  ..., -0.0264,  0.0648,  0.0621],\n",
      "        [-0.0687, -0.0002,  0.0274,  ..., -0.0676,  0.0239,  0.0451],\n",
      "        [-0.0439, -0.0542,  0.0012,  ..., -0.0443,  0.0428,  0.0373],\n",
      "        ...,\n",
      "        [-0.0796, -0.0169, -0.0234,  ..., -0.0294,  0.0359,  0.0713],\n",
      "        [-0.0550, -0.0619,  0.0151,  ..., -0.0183,  0.0187,  0.0700],\n",
      "        [-0.0971, -0.0117,  0.0673,  ..., -0.0438,  0.0950,  0.0476]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0740, -0.0139,  0.0574,  ..., -0.0529,  0.0372,  0.0309],\n",
      "        [-0.0464, -0.0627,  0.0114,  ..., -0.0450,  0.0580,  0.0731],\n",
      "        [-0.0288, -0.0276,  0.0824,  ..., -0.0819,  0.0653,  0.0443],\n",
      "        ...,\n",
      "        [-0.0478, -0.0070,  0.0796,  ..., -0.0801,  0.0946,  0.0253],\n",
      "        [-0.0741,  0.0015,  0.0061,  ..., -0.0797,  0.0739,  0.0404],\n",
      "        [-0.0798, -0.0249,  0.0236,  ..., -0.0285,  0.0811,  0.0750]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1405,  0.0252,  0.0383,  ..., -0.0213,  0.1573,  0.0144],\n",
      "        [-0.0761, -0.0470,  0.0672,  ..., -0.0635,  0.1172,  0.0187],\n",
      "        [-0.0805, -0.0542,  0.0990,  ..., -0.0826,  0.0875,  0.0407],\n",
      "        ...,\n",
      "        [-0.1494,  0.0542,  0.0669,  ..., -0.0714,  0.1160,  0.0018],\n",
      "        [-0.1445,  0.0138,  0.0519,  ..., -0.0072,  0.1089, -0.0041],\n",
      "        [-0.0929, -0.0232,  0.0182,  ..., -0.0131,  0.0710,  0.0194]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-9.3972e-02, -7.7465e-03,  1.3820e-01,  ..., -1.2301e-01,\n",
      "          1.7743e-01, -3.4796e-02],\n",
      "        [-7.1768e-02,  2.3151e-02,  1.0561e-01,  ..., -8.4736e-02,\n",
      "          1.1769e-01, -2.2014e-02],\n",
      "        [-4.2894e-02, -2.9654e-02,  6.2216e-02,  ..., -9.6600e-02,\n",
      "          2.8144e-02,  1.0566e-04],\n",
      "        ...,\n",
      "        [-1.1314e-01,  1.4972e-02,  3.2669e-02,  ..., -8.4223e-02,\n",
      "          5.3279e-02,  4.7897e-02],\n",
      "        [-6.8965e-02, -6.8731e-02,  3.7011e-02,  ..., -4.9722e-02,\n",
      "          1.1852e-01,  6.0875e-02],\n",
      "        [-1.6432e-01,  2.5846e-03,  8.6251e-02,  ..., -3.2470e-02,\n",
      "          1.1755e-01, -7.3680e-03]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0708, -0.0652,  0.1042,  ..., -0.0627,  0.1636, -0.0191],\n",
      "        [-0.0187, -0.0780,  0.0485,  ..., -0.0346,  0.1986,  0.0333],\n",
      "        [-0.0803,  0.0116,  0.0823,  ..., -0.0812,  0.2575, -0.0160],\n",
      "        ...,\n",
      "        [ 0.0681, -0.0957,  0.0594,  ..., -0.0029,  0.0838, -0.0141],\n",
      "        [-0.0546, -0.0227,  0.0262,  ...,  0.0032,  0.1558,  0.0471],\n",
      "        [-0.0776, -0.0289,  0.0141,  ...,  0.0231,  0.1741,  0.0655]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1725,  0.0548,  0.0323,  ..., -0.0063,  0.1447, -0.0194],\n",
      "        [-0.0265,  0.0136,  0.1264,  ..., -0.1073,  0.1419,  0.0053],\n",
      "        [ 0.0188, -0.0517,  0.0894,  ..., -0.0314,  0.1602, -0.0693],\n",
      "        ...,\n",
      "        [ 0.0906, -0.0854,  0.0817,  ..., -0.0967,  0.1290,  0.0057],\n",
      "        [ 0.2340, -0.1413,  0.1347,  ..., -0.0478,  0.1655, -0.0148],\n",
      "        [ 0.0736, -0.0157,  0.1676,  ..., -0.0941,  0.1999, -0.0552]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0408,  0.1702,  0.1252,  ..., -0.0445,  0.2825, -0.0585],\n",
      "        [-0.0364,  0.0428,  0.0962,  ...,  0.0133,  0.4711, -0.0929],\n",
      "        [ 0.3878, -0.1718,  0.2183,  ..., -0.1170,  0.2219, -0.1052],\n",
      "        ...,\n",
      "        [ 0.0526, -0.0829,  0.0537,  ..., -0.0413,  0.1201,  0.0120],\n",
      "        [-0.0772,  0.0485,  0.0755,  ..., -0.0076,  0.2206, -0.0786],\n",
      "        [ 0.1201,  0.0094,  0.1484,  ..., -0.0865,  0.3822, -0.0568]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4276, -0.2416,  0.0498,  ..., -0.0030,  0.2469, -0.1291],\n",
      "        [ 0.6045, -0.3277,  0.1913,  ..., -0.0979,  0.2969, -0.1584],\n",
      "        [ 0.2083,  0.0232,  0.2250,  ..., -0.1874,  0.3559, -0.1564],\n",
      "        ...,\n",
      "        [ 0.3689, -0.1133,  0.2285,  ...,  0.0047,  0.3753, -0.2026],\n",
      "        [-0.0553,  0.2452,  0.1184,  ..., -0.0643,  0.2990, -0.0666],\n",
      "        [ 0.3361,  0.0720,  0.2226,  ..., -0.1901,  0.4913, -0.1785]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1776,  0.2692,  0.1353,  ..., -0.0389,  0.3405, -0.0929],\n",
      "        [ 0.0347,  0.0588,  0.0937,  ...,  0.1617,  0.4972, -0.0506],\n",
      "        [ 0.1867, -0.0218,  0.0414,  ...,  0.1196,  0.3775, -0.0794],\n",
      "        ...,\n",
      "        [ 0.2581, -0.2772, -0.0146,  ...,  0.2350,  0.2905, -0.0468],\n",
      "        [ 0.3224, -0.1483,  0.1320,  ..., -0.1017,  0.3972, -0.1329],\n",
      "        [ 0.2764, -0.1549,  0.1600,  ...,  0.0335,  0.3503, -0.0536]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2293,  0.1322,  0.2840,  ..., -0.1248,  0.5754, -0.1746],\n",
      "        [-0.0834,  0.4147,  0.1706,  ..., -0.0289,  0.5759, -0.1591],\n",
      "        [ 0.4056, -0.1427,  0.2111,  ..., -0.1268,  0.3601, -0.2203],\n",
      "        ...,\n",
      "        [ 0.2657,  0.0310,  0.2724,  ...,  0.1025,  0.8668, -0.2376],\n",
      "        [ 0.1340,  0.1541,  0.1493,  ..., -0.0848,  0.3993, -0.1660],\n",
      "        [ 0.2303, -0.0030,  0.2305,  ..., -0.0208,  0.7126, -0.2213]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8112, -0.5403,  0.1250,  ...,  0.0959,  0.3876, -0.2166],\n",
      "        [ 0.5978, -0.1122,  0.4761,  ..., -0.3487,  0.5155, -0.3685],\n",
      "        [ 0.5266, -0.3288, -0.0018,  ..., -0.0275,  0.3855, -0.1397],\n",
      "        ...,\n",
      "        [-0.0885,  0.1294,  0.1166,  ..., -0.0142,  0.4893, -0.1804],\n",
      "        [ 0.3098, -0.2609, -0.0993,  ...,  0.1255,  0.3668, -0.0052],\n",
      "        [-0.0730,  0.0752,  0.0632,  ...,  0.3633,  0.6605, -0.1887]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2243, -0.1471, -0.2552,  ...,  0.3050,  0.4429, -0.0935],\n",
      "        [ 0.4802, -0.2167,  0.1110,  ..., -0.0494,  0.6112, -0.3522],\n",
      "        [ 0.1084,  0.1181,  0.0620,  ...,  0.2394,  0.7243, -0.2983],\n",
      "        ...,\n",
      "        [ 0.3853, -0.4942, -0.0879,  ...,  0.0985,  0.3889, -0.0353],\n",
      "        [-0.2035,  0.5240,  0.2804,  ..., -0.0189,  0.7974, -0.3199],\n",
      "        [ 1.1950, -0.5437,  0.1802,  ..., -0.1116,  0.5933, -0.4312]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1753,  0.4574,  0.3355,  ..., -0.0312,  0.7059, -0.3256],\n",
      "        [ 0.8392, -0.7709,  0.0288,  ..., -0.0168,  0.2826, -0.2122],\n",
      "        [ 0.6029, -0.5878, -0.0743,  ...,  0.0968,  0.7289, -0.3211],\n",
      "        ...,\n",
      "        [-0.0834,  0.0067, -0.2043,  ...,  0.2959,  0.6319, -0.2396],\n",
      "        [-0.1823,  0.3515, -0.0118,  ...,  0.0323,  0.4493, -0.1680],\n",
      "        [-0.2117,  0.5241,  0.0693,  ...,  0.1134,  0.6631, -0.2370]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2548, -0.0910, -0.2217,  ...,  0.1756,  0.3535, -0.4062],\n",
      "        [ 0.5800, -0.5952, -0.4002,  ...,  0.0291,  0.3845, -0.3105],\n",
      "        [-0.3521,  0.6818,  0.1256,  ..., -0.0686,  0.6550, -0.3646],\n",
      "        ...,\n",
      "        [ 0.0998, -0.0293,  0.1511,  ..., -0.2104,  0.5923, -0.4526],\n",
      "        [ 1.1792, -0.7373, -0.0082,  ..., -0.1688,  0.3481, -0.4411],\n",
      "        [ 1.5716, -1.0538, -0.1174,  ..., -0.2012,  0.2480, -0.5631]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2021, -0.2127,  0.0640,  ..., -0.2177,  0.2556, -0.2761],\n",
      "        [-0.6150,  0.8268,  0.0467,  ..., -0.1533,  0.7734, -0.3605],\n",
      "        [ 1.1518, -1.2487, -0.1763,  ...,  0.1095,  0.0347, -0.2898],\n",
      "        ...,\n",
      "        [ 0.2512, -0.5632, -0.6529,  ...,  0.8503,  0.4417, -0.1685],\n",
      "        [ 0.5588, -0.7485, -0.1926,  ..., -0.0276,  0.2395, -0.1315],\n",
      "        [ 1.4994, -1.1476, -0.1145,  ..., -0.2017,  0.1896, -0.3678]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7790, -0.8109, -0.0165,  ..., -0.2830,  0.2004, -0.3597],\n",
      "        [ 1.2763, -1.3165, -0.2234,  ..., -0.0694, -0.0305, -0.2660],\n",
      "        [ 0.0641,  0.2580, -0.0338,  ..., -0.1235,  0.2391, -0.4215],\n",
      "        ...,\n",
      "        [ 0.3441,  0.1340,  0.0837,  ..., -0.4442,  0.4741, -0.4524],\n",
      "        [-0.4251,  0.7712,  0.1136,  ..., -0.2066,  0.4834, -0.3183],\n",
      "        [ 0.4118, -0.7774, -0.2601,  ...,  0.0246,  0.1714, -0.0815]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0565,  0.0882,  0.0658,  ..., -0.5895,  0.3099, -0.3805],\n",
      "        [-0.3863,  0.5982,  0.1080,  ...,  0.1736,  0.5643, -0.3481],\n",
      "        [ 0.4170, -0.1787,  0.0268,  ..., -0.5014,  0.1460, -0.2870],\n",
      "        ...,\n",
      "        [ 0.3183, -0.1722,  0.0702,  ..., -0.5714,  0.2283, -0.2485],\n",
      "        [ 0.1907, -0.1610,  0.2247,  ..., -0.7069,  0.4457, -0.5345],\n",
      "        [ 0.1156, -0.2533, -0.1319,  ..., -0.0945,  0.0940, -0.3015]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1889, -0.4105, -0.6432,  ...,  0.9835,  0.2798, -0.0616],\n",
      "        [-0.7642,  0.0206, -0.2909,  ...,  1.2988,  0.7216, -0.4085],\n",
      "        [-0.0774, -0.5687, -0.7222,  ...,  0.7433,  0.2351,  0.0887],\n",
      "        ...,\n",
      "        [ 0.3495, -0.5987,  0.0508,  ..., -0.1761,  0.1827, -0.4560],\n",
      "        [-0.6511,  0.3617,  0.3691,  ..., -0.3346,  0.9074, -0.5505],\n",
      "        [ 0.5088, -0.6513, -0.3353,  ...,  0.0978, -0.1507, -0.1814]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ 2.1391, -1.6669,  0.2740,  ..., -0.5904, -0.4814, -0.6944],\n",
      "        [-0.8917,  0.4030,  0.2129,  ...,  0.1712,  1.1142, -0.2983],\n",
      "        [-1.0469,  1.6374,  0.7306,  ..., -0.2192,  1.1301, -0.6257],\n",
      "        ...,\n",
      "        [-0.8164,  0.4706,  0.3848,  ...,  0.3017,  0.9609, -0.4871],\n",
      "        [-0.1559, -0.3351,  0.3942,  ..., -0.3683,  0.4043, -0.3315],\n",
      "        [ 1.2007, -0.9511,  1.3458,  ..., -0.7154,  0.0744, -1.0610]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[ 4.6345e-01,  1.1797e-01,  1.4414e+00,  ..., -4.6224e-01,\n",
      "          3.7950e-01, -8.7933e-01],\n",
      "        [-4.5607e-01,  5.9770e-01, -3.0355e-02,  ...,  3.4387e-01,\n",
      "          4.1871e-01, -4.4505e-01],\n",
      "        [ 5.1864e-01, -1.2921e+00, -3.7545e-01,  ...,  5.2550e-01,\n",
      "         -7.1280e-02,  1.0942e-01],\n",
      "        ...,\n",
      "        [ 3.2730e-01,  1.0234e-03,  1.2438e+00,  ..., -8.3164e-01,\n",
      "          2.2170e-01, -7.1500e-01],\n",
      "        [ 1.9737e-01, -6.8372e-01, -2.5054e-01,  ...,  6.5946e-01,\n",
      "          1.0221e-01, -8.2354e-02],\n",
      "        [-1.3888e+00,  1.1833e+00, -9.2965e-02,  ...,  4.7177e-01,\n",
      "          7.9345e-01, -2.5807e-01]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.0208e+00, -2.5104e-01, -6.4514e-01,  ...,  2.1211e+00,\n",
      "          8.6249e-01, -1.6191e-01],\n",
      "        [-9.7951e-01,  1.5568e-01, -4.9236e-01,  ...,  1.2691e+00,\n",
      "          7.6991e-01,  1.5304e-01],\n",
      "        [ 4.3922e-03, -8.6984e-01, -6.1917e-01,  ...,  1.4914e+00,\n",
      "          3.7097e-01,  3.3379e-01],\n",
      "        ...,\n",
      "        [-7.4198e-01,  1.4655e-03, -2.5566e-01,  ...,  8.1860e-01,\n",
      "          8.9673e-01,  8.3186e-02],\n",
      "        [-1.4366e+00,  1.2475e+00, -1.0641e-01,  ...,  5.4222e-01,\n",
      "          8.5501e-01, -5.8003e-02],\n",
      "        [-5.5465e-02, -9.6643e-01, -5.4141e-01,  ...,  1.8198e+00,\n",
      "          4.4154e-01,  2.3270e-01]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.7203,  1.6598,  0.2033,  ...,  1.2316,  1.3145, -0.4212],\n",
      "        [ 1.7505, -3.0939, -0.1503,  ..., -0.1873, -0.3579, -0.1154],\n",
      "        [-1.4251,  1.1322,  1.7710,  ...,  0.3242,  1.4750, -0.9561],\n",
      "        ...,\n",
      "        [-0.8877, -0.0132,  0.7774,  ...,  0.6344,  0.8089, -0.7114],\n",
      "        [-0.0483, -1.0220, -0.5115,  ...,  0.9995,  0.5047,  0.3813],\n",
      "        [-2.1254,  1.7847, -0.3371,  ...,  0.7816,  1.2370,  0.0834]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.4145,  0.0098, -1.1709,  ...,  1.1338,  0.8950,  0.6607],\n",
      "        [-1.3097, -0.0852, -1.1130,  ...,  1.8052,  0.9127,  0.6912],\n",
      "        [-0.2512, -1.5557, -1.2443,  ...,  1.2461,  0.2046,  1.0537],\n",
      "        ...,\n",
      "        [ 0.7415, -2.2415,  0.0138,  ...,  0.3888, -0.4191, -0.0698],\n",
      "        [-0.4253, -1.6061,  0.7425,  ...,  1.1039,  0.1993, -0.4234],\n",
      "        [-0.5809, -0.0667,  0.5702,  ...,  0.7523,  0.5452, -0.1744]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-cdc69b63eb66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_generators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST_DATA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\trial.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCALLBACK_LIST\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCallbackListInjection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprinter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback_list_old\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCALLBACK_LIST\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallback_list_old\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\trial.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, epochs, verbose)\u001b[0m\n\u001b[0;32m    986\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCALLBACK_LIST\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_start_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 988\u001b[1;33m                 \u001b[0mfinal_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMETRICS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    990\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTOP_TRAINING\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\trial.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTEPS\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\trial.py\u001b[0m in \u001b[0;36m_fit_pass\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m   1027\u001b[0m         \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCALLBACK_LIST\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_start_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBATCH\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTEPS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTEPS\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m             \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAMPLER\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m             \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCALLBACK_LIST\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchbearer\\trial.py\u001b[0m in \u001b[0;36mload_batch_standard\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mstate\u001b[0m \u001b[0mdict\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTrial\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \"\"\"\n\u001b[1;32m--> 214\u001b[1;33m     state[torchbearer.X], state[torchbearer.Y_TRUE] = deep_to(next(state[torchbearer.ITERATOR]),\n\u001b[0m\u001b[0;32m    215\u001b[0m                                                               \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorchbearer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m                                                               state[torchbearer.DATA_TYPE])\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \"\"\"\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#reset the data loaders\n",
    "torch.manual_seed(seed)\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=128, shuffle=True)\n",
    "\n",
    "# build the model\n",
    "model = BetterCNN()\n",
    "\n",
    "# define the loss function and the optimiser\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimiser = optim.Adam(model.parameters())\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "trial = Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)\n",
    "trial.with_generators(trainloader, test_generator=testloader)\n",
    "trial.run(epochs=10)\n",
    "results = trial.evaluate(data_key=torchbearer.TEST_DATA)\n",
    "print(results)\n",
    "\n",
    "assert results['test_acc'] > 0.99\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c2baca3abcdbfc058a657e165a1cf8e3",
     "grade": false,
     "grade_id": "cell-1c2475b8550316a4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "If correctly implemented you should see this slightly larger model achieves the respectable classification accuracy of 99.13%.\n",
    "\n",
    "## Saving models\n",
    "\n",
    "Being able to train a model is fine, but in practice once we've trained the model we probably want to save the result so we can reuse it at a later time. PyTorch makes saving the model easy using the `torch.save(state, filepath)` function. This will save the weights of the model so they can be loaded into a new instance at a later point. \n",
    "\n",
    "__Run the following code to save the weights for use in the next part of the lab.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4895367de85f19ae1bb89e90ad300e70",
     "grade": false,
     "grade_id": "cell-6d81f64d4d65498c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#save the trained model weights\n",
    "torch.save(model.state_dict(), \"./bettercnn.weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5152e5288466c2af37eb11d3393c5446",
     "grade": false,
     "grade_id": "cell-35c249867f1ec1d2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "__If you are running on Colab, run the following to download the weights to the local machine:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c75f37cdabf24f935575dcb026f3c6f3",
     "grade": false,
     "grade_id": "cell-957d645048f13f7a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('bettercnn.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # convert to tensor\n",
    "])\n",
    "trainset = MNIST(\".\", train=True, download=True, transform=transform)\n",
    "testset = MNIST(\".\", train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
      "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
      "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
      "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
      "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
      "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
      "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
      "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
      "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
      "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
      "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
      "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
      "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]]), 5)\n"
     ]
    }
   ],
   "source": [
    "print(trainset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
